2024-10-29 16:24:04,517: Namespace(device='cuda', alpha=0.8, beta=1.0, lr=0.0001, pretrain_epochs=0, num_epochs=5, model='vit', noise_strength=0.1, no_adversarial=False, visualize=False, debug=False, no_cam=True, seed=42, threshold=0.5, positive_weight=1.05, dataset='mimic-cxr', feature='test')
2024-10-29 16:24:04,639: Number of GPUs available: 8
2024-10-29 16:24:06,975: Successfully load model!
2024-10-29 16:24:08,097: Number of samples in training dataset: 81999 | testing dataset:9111
2024-10-29 16:24:08,098: positive weight: 16.1492
2024-10-29 16:24:55,085: Test Loss: 0.6850, Accuracy: 0.9382, F1: 0.0175, AUC: 0.5510
2024-10-29 16:24:55,086: DP:0.00, EO:0.01
2024-10-29 16:25:06,747: Step [20/2563], Loss D: 0.8558, Loss G: -0.7964
2024-10-29 16:25:13,606: Step [40/2563], Loss D: 0.7063, Loss G: 0.0256
2024-10-29 16:25:20,938: Step [60/2563], Loss D: 0.4615, Loss G: -0.3773
2024-10-29 16:25:28,225: Step [80/2563], Loss D: 0.4805, Loss G: -0.0952
2024-10-29 16:25:35,517: Step [100/2563], Loss D: 0.5802, Loss G: -0.1768
2024-10-29 16:25:42,783: Step [120/2563], Loss D: 0.4880, Loss G: -0.4710
2024-10-29 16:25:50,110: Step [140/2563], Loss D: 0.3470, Loss G: 0.1074
2024-10-29 16:25:57,367: Step [160/2563], Loss D: 0.3660, Loss G: -0.4142
2024-10-29 16:26:04,632: Step [180/2563], Loss D: 0.7369, Loss G: 0.0116
2024-10-29 16:26:11,860: Step [200/2563], Loss D: 0.3221, Loss G: -0.3163
2024-10-29 16:26:19,106: Step [220/2563], Loss D: 0.5026, Loss G: -0.1821
2024-10-29 16:26:26,316: Step [240/2563], Loss D: 0.4082, Loss G: -0.0712
2024-10-29 16:26:33,526: Step [260/2563], Loss D: 0.4922, Loss G: -0.0525
2024-10-29 16:26:40,799: Step [280/2563], Loss D: 0.3302, Loss G: -0.1192
2024-10-29 16:26:48,039: Step [300/2563], Loss D: 0.5072, Loss G: -0.1633
2024-10-29 16:26:55,369: Step [320/2563], Loss D: 0.6178, Loss G: -0.0381
2024-10-29 16:27:02,662: Step [340/2563], Loss D: 1.0107, Loss G: -0.0934
2024-10-29 16:27:09,902: Step [360/2563], Loss D: 0.6038, Loss G: -0.0636
2024-10-29 16:27:17,115: Step [380/2563], Loss D: 0.5603, Loss G: -0.1612
2024-10-29 16:27:24,483: Step [400/2563], Loss D: 0.4690, Loss G: 0.0706
2024-10-29 16:27:31,862: Step [420/2563], Loss D: 0.3455, Loss G: 0.0467
2024-10-29 16:27:39,236: Step [440/2563], Loss D: 0.4096, Loss G: -0.4447
2024-10-29 16:27:46,574: Step [460/2563], Loss D: 0.3443, Loss G: -0.0372
2024-10-29 16:27:53,905: Step [480/2563], Loss D: 0.5180, Loss G: 0.0462
2024-10-29 16:28:01,235: Step [500/2563], Loss D: 0.3783, Loss G: -0.1532
2024-10-29 16:28:08,481: Step [520/2563], Loss D: 0.4096, Loss G: -0.1147
2024-10-29 16:28:15,874: Step [540/2563], Loss D: 0.3662, Loss G: 0.0835
2024-10-29 16:28:23,308: Step [560/2563], Loss D: 0.5238, Loss G: 0.0583
2024-10-29 16:28:30,736: Step [580/2563], Loss D: 0.6291, Loss G: 0.2375
2024-10-29 16:28:38,174: Step [600/2563], Loss D: 0.3519, Loss G: 0.1000
2024-10-29 16:28:45,607: Step [620/2563], Loss D: 0.1901, Loss G: 0.1275
2024-10-29 16:28:52,965: Step [640/2563], Loss D: 0.2344, Loss G: 0.3219
2024-10-29 16:29:00,392: Step [660/2563], Loss D: 0.2074, Loss G: 0.0515
2024-10-29 16:29:07,753: Step [680/2563], Loss D: 0.5421, Loss G: 0.3469
2024-10-29 16:29:15,060: Step [700/2563], Loss D: 0.3564, Loss G: -0.2232
2024-10-29 16:29:22,376: Step [720/2563], Loss D: 0.3879, Loss G: -0.0785
2024-10-29 16:29:29,693: Step [740/2563], Loss D: 1.0130, Loss G: -0.2581
2024-10-29 16:29:37,003: Step [760/2563], Loss D: 0.6624, Loss G: -0.0604
2024-10-29 16:29:44,249: Step [780/2563], Loss D: 0.5104, Loss G: 0.1546
2024-10-29 16:29:51,595: Step [800/2563], Loss D: 0.3194, Loss G: 0.0750
2024-10-29 16:29:58,946: Step [820/2563], Loss D: 0.4382, Loss G: 0.0455
2024-10-29 16:30:06,345: Step [840/2563], Loss D: 0.3148, Loss G: -0.0477
2024-10-29 16:30:13,742: Step [860/2563], Loss D: 0.2140, Loss G: 0.1021
2024-10-29 16:30:21,174: Step [880/2563], Loss D: 0.5514, Loss G: -0.0126
2024-10-29 16:30:28,559: Step [900/2563], Loss D: 0.3380, Loss G: 0.1399
2024-10-29 16:30:35,965: Step [920/2563], Loss D: 0.3911, Loss G: 0.2782
2024-10-29 16:30:43,344: Step [940/2563], Loss D: 0.6234, Loss G: -0.1537
2024-10-29 16:30:50,684: Step [960/2563], Loss D: 0.3259, Loss G: 0.1139
2024-10-29 16:30:58,009: Step [980/2563], Loss D: 0.7130, Loss G: -0.1472
2024-10-29 16:31:05,351: Step [1000/2563], Loss D: 0.2532, Loss G: 0.1431
2024-10-29 16:31:12,801: Step [1020/2563], Loss D: 0.6195, Loss G: -0.1058
2024-10-29 16:31:20,283: Step [1040/2563], Loss D: 0.4075, Loss G: 0.2929
2024-10-29 16:31:27,731: Step [1060/2563], Loss D: 0.5047, Loss G: -0.1075
2024-10-29 16:31:35,194: Step [1080/2563], Loss D: 0.3457, Loss G: 0.0772
2024-10-29 16:31:42,558: Step [1100/2563], Loss D: 0.3584, Loss G: -0.3831
2024-10-29 16:31:49,937: Step [1120/2563], Loss D: 0.6076, Loss G: 0.0708
2024-10-29 16:31:57,246: Step [1140/2563], Loss D: 0.3285, Loss G: 0.0926
2024-10-29 16:32:04,518: Step [1160/2563], Loss D: 0.4406, Loss G: 0.0979
2024-10-29 16:32:11,814: Step [1180/2563], Loss D: 0.5906, Loss G: 0.1381
2024-10-29 16:32:19,211: Step [1200/2563], Loss D: 0.4500, Loss G: 0.0829
2024-10-29 16:32:26,699: Step [1220/2563], Loss D: 0.2983, Loss G: -0.2794
2024-10-29 16:32:34,049: Step [1240/2563], Loss D: 0.3449, Loss G: 0.2260
2024-10-29 16:32:41,541: Step [1260/2563], Loss D: 0.4036, Loss G: 0.1981
2024-10-29 16:32:48,940: Step [1280/2563], Loss D: 0.2946, Loss G: -0.1446
2024-10-29 16:32:56,301: Step [1300/2563], Loss D: 0.2654, Loss G: -0.0122
2024-10-29 16:33:03,613: Step [1320/2563], Loss D: 0.3014, Loss G: -0.0810
2024-10-29 16:33:10,710: Step [1340/2563], Loss D: 0.4274, Loss G: -0.0448
2024-10-29 16:33:17,971: Step [1360/2563], Loss D: 0.2942, Loss G: 0.0700
2024-10-29 16:33:25,324: Step [1380/2563], Loss D: 0.6603, Loss G: -0.3189
2024-10-29 16:33:32,666: Step [1400/2563], Loss D: 0.1605, Loss G: 0.0572
2024-10-29 16:33:40,015: Step [1420/2563], Loss D: 0.5085, Loss G: 0.0709
2024-10-29 16:33:47,342: Step [1440/2563], Loss D: 0.3680, Loss G: -0.0426
2024-10-29 16:33:54,555: Step [1460/2563], Loss D: 0.2857, Loss G: -0.1743
2024-10-29 16:34:01,545: Step [1480/2563], Loss D: 0.4313, Loss G: -0.0067
2024-10-29 16:34:08,464: Step [1500/2563], Loss D: 0.2991, Loss G: 0.0918
2024-10-29 16:34:17,265: Step [1520/2563], Loss D: 0.3061, Loss G: 0.0633
2024-10-29 16:34:24,579: Step [1540/2563], Loss D: 0.3605, Loss G: 0.3431
2024-10-29 16:34:31,858: Step [1560/2563], Loss D: 0.4314, Loss G: -0.2199
2024-10-29 16:34:39,149: Step [1580/2563], Loss D: 0.4815, Loss G: 0.2697
2024-10-29 16:34:46,515: Step [1600/2563], Loss D: 0.2806, Loss G: -0.0138
2024-10-29 16:34:55,606: Step [1620/2563], Loss D: 0.3993, Loss G: -0.0173
2024-10-29 16:35:13,508: Step [1640/2563], Loss D: 0.1860, Loss G: 0.0740
2024-10-29 16:35:24,871: Step [1660/2563], Loss D: 0.3829, Loss G: 0.1784
2024-10-29 16:35:36,520: Step [1680/2563], Loss D: 0.3474, Loss G: -0.0875
2024-10-29 16:35:49,427: Step [1700/2563], Loss D: 0.3874, Loss G: -0.1265
2024-10-29 16:37:01,484: Step [1720/2563], Loss D: 0.2944, Loss G: 0.2193
